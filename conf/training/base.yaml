# Base training configuration (reusable)
batch_size: 16
learning_rate: 0.001 # 1e-3
epochs: 100
optimizer: 'adam'

# Model architecture
hidden_dims: [512, 256, 64]
dropout: 0.3

# Training control
patience: 5  # Early stopping patience
